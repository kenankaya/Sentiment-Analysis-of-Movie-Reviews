{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wrapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-) Data Preprocessing 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv(\"train.tsv\",sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The numbers in the sentiment  column go from 0 to 4.\n",
    "\n",
    "\n",
    "* These number  scaled the comments  from most negative to  most positive.\n",
    "\n",
    "\n",
    "* Here we will recreate the sentiment column so that the numbers 0 and 1 represent a negative comment.\n",
    " \n",
    " \n",
    "* Here we will recreate the sentiment column so that the numbers 3 and 4 represent a positive comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Sentiment\"].replace(0, \"negative\", inplace = True)\n",
    "data[\"Sentiment\"].replace(1, \"negative\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Sentiment\"].replace(3,  \"pozitive\", inplace = True)\n",
    "data[\"Sentiment\"].replace(4,  \"pozitive\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "  Sentiment  \n",
       "0  negative  \n",
       "1         2  \n",
       "2         2  \n",
       "3         2  \n",
       "4         2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will removed the middle-valued comments, which are represented by values of 2 under the sentiment column, from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data[\"Sentiment\"] == \"negative\") | (data[\"Sentiment\"] == \"pozitive\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>good for the goose</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>the gander , some of which occasionally amuses...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>amuses</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId                                             Phrase  \\\n",
       "0          1           1  A series of escapades demonstrating the adage ...   \n",
       "21        22           1                                 good for the goose   \n",
       "22        23           1                                               good   \n",
       "33        34           1  the gander , some of which occasionally amuses...   \n",
       "46        47           1                                             amuses   \n",
       "\n",
       "   Sentiment  \n",
       "0   negative  \n",
       "21  pozitive  \n",
       "22  pozitive  \n",
       "33  negative  \n",
       "46  pozitive  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>34345</td>\n",
       "      <td>34345</td>\n",
       "      <td>34345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pozitive</th>\n",
       "      <td>42133</td>\n",
       "      <td>42133</td>\n",
       "      <td>42133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           PhraseId  SentenceId  Phrase\n",
       "Sentiment                              \n",
       "negative      34345       34345   34345\n",
       "pozitive      42133       42133   42133"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"Sentiment\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"text\"] = data[\"Phrase\"]\n",
    "df[\"label\"] = data[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>good for the goose</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>good</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>the gander , some of which occasionally amuses...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>amuses</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text     label\n",
       "0   A series of escapades demonstrating the adage ...  negative\n",
       "21                                 good for the goose  pozitive\n",
       "22                                               good  pozitive\n",
       "33  the gander , some of which occasionally amuses...  negative\n",
       "46                                             amuses  pozitive"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-) Data Preprocessing 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1-)Converting all letters into Lowercase in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: \" \".join(i.lower() for i in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>good for the goose</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>good</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>the gander , some of which occasionally amuses...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>amuses</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text     label\n",
       "0   a series of escapades demonstrating the adage ...  negative\n",
       "21                                 good for the goose  pozitive\n",
       "22                                               good  pozitive\n",
       "33  the gander , some of which occasionally amuses...  negative\n",
       "46                                             amuses  pozitive"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2-)Deleting Punctuation Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>good for the goose</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>good</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>the gander  some of which occasionally amuses ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>amuses</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text     label\n",
       "0   a series of escapades demonstrating the adage ...  negative\n",
       "21                                 good for the goose  pozitive\n",
       "22                                               good  pozitive\n",
       "33  the gander  some of which occasionally amuses ...  negative\n",
       "46                                             amuses  pozitive"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3-) Deleting Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('\\d','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>good for the goose</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>good</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>the gander  some of which occasionally amuses ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>amuses</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text     label\n",
       "0   a series of escapades demonstrating the adage ...  negative\n",
       "21                                 good for the goose  pozitive\n",
       "22                                               good  pozitive\n",
       "33  the gander  some of which occasionally amuses ...  negative\n",
       "46                                             amuses  pozitive"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4-)Deleting Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: \" \".join(i for i in x.split() if i not in sw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>series escapades demonstrating adage good goos...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>good goose</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>good</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>gander occasionally amuses none amounts much s...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>amuses</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text     label\n",
       "0   series escapades demonstrating adage good goos...  negative\n",
       "21                                         good goose  pozitive\n",
       "22                                               good  pozitive\n",
       "33  gander occasionally amuses none amounts much s...  negative\n",
       "46                                             amuses  pozitive"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5-)Deleting of words with low frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=pd.Series(' '.join(df['text']).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                series\n",
       "1             escapades\n",
       "2         demonstrating\n",
       "3                 adage\n",
       "4                  good\n",
       "              ...      \n",
       "380800           forced\n",
       "380801        avuncular\n",
       "380802         chortles\n",
       "380803        avuncular\n",
       "380804         chortles\n",
       "Length: 380805, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "film                   4531\n",
       "movie                  4011\n",
       "nt                     2689\n",
       "one                    2326\n",
       "like                   1961\n",
       "                       ... \n",
       "jerusalem                 1\n",
       "socialeconomicurban       1\n",
       "jeong                     1\n",
       "products                  1\n",
       "departs                   1\n",
       "Length: 15826, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.value_counts()# frequency of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "film          4531\n",
       "movie         4011\n",
       "nt            2689\n",
       "one           2326\n",
       "like          1961\n",
       "              ... \n",
       "absolutely      70\n",
       "brown           70\n",
       "dream           70\n",
       "generally       70\n",
       "oddly           70\n",
       "Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.value_counts()[0:1000]# words with the highest frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clicks                 2\n",
       "onenight               2\n",
       "leaner                 2\n",
       "bob                    2\n",
       "ferris                 2\n",
       "                      ..\n",
       "jerusalem              1\n",
       "socialeconomicurban    1\n",
       "jeong                  1\n",
       "products               1\n",
       "departs                1\n",
       "Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deleting_words=words.value_counts()[-1000:]# words with the lowest frequency\n",
    "deleting_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']= df['text'].apply(lambda x: \" \".join(i for i in x.split() if i not in deleting_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>series demonstrating adage good goose also goo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>good goose</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>good</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>gander occasionally amuses none amounts much s...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>amuses</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text     label\n",
       "0   series demonstrating adage good goose also goo...  negative\n",
       "21                                         good goose  pozitive\n",
       "22                                               good  pozitive\n",
       "33  gander occasionally amuses none amounts much s...  negative\n",
       "46                                             amuses  pozitive"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6-)Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>series demonstrating adage good goose also goo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>good goose</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>good</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>gander occasionally amuses none amount much story</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>amuses</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text     label\n",
       "0   series demonstrating adage good goose also goo...  negative\n",
       "21                                         good goose  pozitive\n",
       "22                                               good  pozitive\n",
       "33  gander occasionally amuses none amount much story  negative\n",
       "46                                             amuses  pozitive"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-)Feature Engeneering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1)CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CountVectorizer is used to convert a collection of text documents to a vector of term/token counts. It also enables the pre-processing of text data prior to generating the vector representation\n",
    "\n",
    "\n",
    "* CountVectorizer  creates uniqe words and its frequencey as columns and rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>series demonstrating adage good goose also goo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>good goose</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>good</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>gander occasionally amuses none amount much story</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>amuses</td>\n",
       "      <td>pozitive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text     label\n",
       "0   series demonstrating adage good goose also goo...  negative\n",
       "21                                         good goose  pozitive\n",
       "22                                               good  pozitive\n",
       "33  gander occasionally amuses none amount much story  negative\n",
       "46                                             amuses  pozitive"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     series demonstrating adage good goose also goo...\n",
       "label                                             negative\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(df[\"text\"],\n",
    "                                                                   df[\"label\"], \n",
    "                                                                    random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118788    pozitive\n",
       "89514     negative\n",
       "86857     pozitive\n",
       "140626    negative\n",
       "153243    pozitive\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = encoder.fit_transform(train_y)\n",
    "test_y = encoder.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0:5] # number 1 represent  positive  comments\n",
    "             # number 0 represent  negative  comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_count = vectorizer.transform(train_x)\n",
    "x_test_count = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaliyah',\n",
       " 'abagnale',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abbass',\n",
       " 'abbott',\n",
       " 'abc',\n",
       " 'abdul',\n",
       " 'abel',\n",
       " 'abhorrent',\n",
       " 'abhors',\n",
       " 'abiding',\n",
       " 'ability',\n",
       " 'abject',\n",
       " 'able']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_count.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3-2) TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _**TF**_ stands for **Term Frequency** \n",
    "\n",
    "* _**IDF**_ stands for **Inverse Data Frequency**\n",
    "\n",
    "\n",
    "* **Term Frequency (TF)**: gives us the frequency of the word in each document in the corpus. It is the ratio of number of times the word appears in a document compared to the total number of words in that document. It increases as the number of occurrences of that word within the document increases.\n",
    "\n",
    "\n",
    "\n",
    "* **Inverse Data Frequency (IDF):** used to calculate the weight of rare words across all documents in the corpus. The words that occur rarely in the corpus have a high IDF score.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Let’s take an example to get a clearer understanding.\n",
    "  * Sentence 1 : The car is driven on the road.\n",
    "  * Sentence 2: The truck is driven on the highway.\n",
    "\n",
    "\n",
    "* In this example, each sentence is a separate document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-media-1.freecodecamp.org/images/1*q3qYevXqQOjJf6Pwdlx8Mw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TF-IDF Vectorizer has 3 levels\n",
    "  * word level\n",
    "  * ngram level \n",
    "  * characters level "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1-) Word Level TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_level_vectorizer = TfidfVectorizer()\n",
    "word_level_vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_word_level = word_level_vectorizer.transform(train_x)\n",
    "x_test_word_level = word_level_vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaliyah',\n",
       " 'abagnale',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abbass',\n",
       " 'abbott',\n",
       " 'abc',\n",
       " 'abdul',\n",
       " 'abel',\n",
       " 'abhorrent',\n",
       " 'abhors',\n",
       " 'abiding',\n",
       " 'ability',\n",
       " 'abject',\n",
       " 'able']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_level_vectorizer.get_feature_names()[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_word_level.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2-) N_gram Level TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(ngram_range=(2, 3))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_vectorizer = TfidfVectorizer(ngram_range = (2,3))\n",
    "ngram_vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ngram = ngram_vectorizer.transform(train_x)\n",
    "x_test_ngram = ngram_vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaliyah one',\n",
       " 'aaliyah one starring',\n",
       " 'abagnale antic',\n",
       " 'abandon hold',\n",
       " 'abandon hold promise',\n",
       " 'abandon hope',\n",
       " 'abandon hope good',\n",
       " 'abandon however',\n",
       " 'abandon however canned',\n",
       " 'abandon leave',\n",
       " 'abandon leave wanting',\n",
       " 'abandon political',\n",
       " 'abandon political madness',\n",
       " 'abandon script',\n",
       " 'abandon script go']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_vectorizer.get_feature_names()[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3-) Characters Level TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char', ngram_range=(2, 3))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_vectorizer = TfidfVectorizer(analyzer = \"char\", ngram_range = (2,3))\n",
    "chars_vectorizer.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_chars =chars_vectorizer.transform(train_x)\n",
    "x_test_chars =chars_vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' a',\n",
       " ' aa',\n",
       " ' ab',\n",
       " ' ac',\n",
       " ' ad',\n",
       " ' ae',\n",
       " ' af',\n",
       " ' ag',\n",
       " ' ah',\n",
       " ' ai',\n",
       " ' ak',\n",
       " ' al',\n",
       " ' am',\n",
       " ' an',\n",
       " ' ap']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_vectorizer.get_feature_names()[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.10803509, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_chars.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-)Sentiment Classification with Machine Learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1-)Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1-) Logistic Regression for CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer  Accuracy Ratio: 0.8368200836820083\n"
     ]
    }
   ],
   "source": [
    "loj = linear_model.LogisticRegression()\n",
    "loj_model = loj.fit(x_train_count, train_y)\n",
    "accuracy = model_selection.cross_val_score(loj_model, \n",
    "                                           x_test_count, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"CountVectorizer  Accuracy Ratio:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2-) Logistic Regression for Word Level TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-Level TF-IDF Vectorizer  Accuracy Ratio: 0.8331066945606695\n"
     ]
    }
   ],
   "source": [
    "loj = linear_model.LogisticRegression()\n",
    "loj_model1 = loj.fit(x_train_word_level,train_y)\n",
    "accuracy1 = model_selection.cross_val_score(loj_model1, \n",
    "                                           x_test_word_level,\n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Word-Level TF-IDF Vectorizer  Accuracy Ratio:\", accuracy1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3-) Logistic Regression for N_gram Level TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-GRAM TF-IDF Vectorizer  Accuracy Ratio: 0.7481694560669456\n"
     ]
    }
   ],
   "source": [
    "loj = linear_model.LogisticRegression()\n",
    "loj_model2 = loj.fit(x_train_ngram,train_y)\n",
    "accuracy2 = model_selection.cross_val_score(loj_model2, \n",
    "                                           x_test_ngram, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"N-GRAM TF-IDF Vectorizer  Accuracy Ratio:\", accuracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2-) Logistic Regression for Characters Level TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters Level TF-IDF Vectorizer Accuracy Ratio: 0.7797071129707113\n"
     ]
    }
   ],
   "source": [
    "loj = linear_model.LogisticRegression()\n",
    "loj_model3 = loj.fit(x_train_chars,train_y)\n",
    "accuracy3 = model_selection.cross_val_score(loj_model3, \n",
    "                                           x_test_chars, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Characters Level TF-IDF Vectorizer Accuracy Ratio:\", accuracy3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2-)Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection , naive_bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1-) Naive Bayes for CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer  Accuracy Ratio: 0.8327928870292887\n"
     ]
    }
   ],
   "source": [
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model = nb.fit(x_train_count,train_y)\n",
    "accuracy4 = model_selection.cross_val_score(nb_model, \n",
    "                                           x_test_count, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"CountVectorizer  Accuracy Ratio:\", accuracy4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2-) Naive Bayes for Word Level TF-IDF Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-Level TF-IDF Vectorizer  Accuracy Ratio: 0.8368200836820083\n"
     ]
    }
   ],
   "source": [
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model1 = nb.fit(x_train_word_level,train_y)\n",
    "accuracy5 = model_selection.cross_val_score(nb_model1, \n",
    "                                           x_test_word_level, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Word-Level TF-IDF Vectorizer  Accuracy Ratio:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3-) Naive Bayes for  N_gram Level TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-GRAM TF-IDF Vectorizer  Accuracy Ratio:: 0.7686192468619246\n"
     ]
    }
   ],
   "source": [
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model2= nb.fit(x_train_ngram,train_y)\n",
    "accuracy6 = model_selection.cross_val_score(nb_model2, \n",
    "                                           x_test_ngram, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"N-GRAM TF-IDF Vectorizer  Accuracy Ratio::\", accuracy6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4-) Naive Bayes for  Characters Level TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters Level TF-IDF Vectorizer Accuracy Ratio: 0.756276150627615\n"
     ]
    }
   ],
   "source": [
    "nb = naive_bayes.MultinomialNB()\n",
    "nb_model3 = nb.fit(x_train_chars,train_y)\n",
    "accuracy7 = model_selection.cross_val_score(nb_model3, \n",
    "                                           x_test_chars, \n",
    "                                           test_y, \n",
    "                                           cv = 10).mean()\n",
    "\n",
    "print(\"Characters Level TF-IDF Vectorizer Accuracy Ratio:\", accuracy7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-) Prediction of the Comments (postive or negative) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * We use **Logistic Regression for CountVectorizer Model** to predict the comments for films  which will be done by audience. Because it has the highset accuracy score  \n",
    " \n",
    " * By using this model , we will predict whether new comment is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loj_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_comments=pd.Series(\"this film is very nice and good i like it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_comments=v.transform(new_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loj_model.predict(new_comments)\n",
    "# number 1 represent positive comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_comments1=pd.Series(\"no not good look at that shit very bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = CountVectorizer()\n",
    "v1.fit(train_x)\n",
    "new_comments1 = v.transform(new_comments1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loj_model.predict(new_comments1)\n",
    "# number 0 represent negative  comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
